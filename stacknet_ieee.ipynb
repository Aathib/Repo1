{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aathib/Repo1/blob/master/stacknet_ieee.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWbXeWHw5hww",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-length",
                  "5492"
                ],
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "2ae3b412-1aa0-4e78-a7d6-9271ad2d4ce5"
      },
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0f502f58-9683-4e03-ad4b-36f943527fae\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-0f502f58-9683-4e03-ad4b-36f943527fae\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"aathibala\",\"key\":\"b629361a9eb4c179a69a6018a9e4e12a\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xawjz0-e-xbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlSgGO0t5h0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "import time\n",
        "from xgboost import XGBClassifier\n",
        "from hyperopt import hp, tpe, STATUS_OK, Trials, fmin\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.pylab import rcParams\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "rcParams['figure.figsize'] = 12, 5\n",
        "import seaborn as sns\n",
        "from lightgbm import LGBMRegressor, LGBMClassifier\n",
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, ExtraTreesClassifier, ExtraTreesRegressor, GradientBoostingClassifier,GradientBoostingRegressor\n",
        "from sklearn.linear_model import LogisticRegression, Ridge\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br9M8Edj5h3A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "128c2029-df67-4298-c696-ca1772083201"
      },
      "source": [
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c ieee-fraud-detection\n",
        "!mkdir train\n",
        "!unzip train_transaction.csv.zip -d train\n",
        "!unzip test_transaction.csv.zip -d train"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train_transaction.csv.zip to /content\n",
            " 84% 44.0M/52.5M [00:01<00:00, 22.3MB/s]\n",
            "100% 52.5M/52.5M [00:01<00:00, 38.9MB/s]\n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.02M [00:00<?, ?B/s]\n",
            "100% 3.02M/3.02M [00:00<00:00, 100MB/s]\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 95% 45.0M/47.3M [00:01<00:00, 24.5MB/s]\n",
            "100% 47.3M/47.3M [00:01<00:00, 40.8MB/s]\n",
            "Downloading test_identity.csv.zip to /content\n",
            "  0% 0.00/2.97M [00:00<?, ?B/s]\n",
            "100% 2.97M/2.97M [00:00<00:00, 98.8MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 149MB/s]\n",
            "mkdir: cannot create directory ‘train’: File exists\n",
            "Archive:  train_transaction.csv.zip\n",
            "  inflating: train/train_transaction.csv  \n",
            "Archive:  test_transaction.csv.zip\n",
            "  inflating: train/test_transaction.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku9XzIVh5h54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('train')\n",
        "data1 = pd.read_csv('train_transaction.csv')\n",
        "test1 = pd.read_csv('test_transaction.csv')\n",
        "data = data1.copy()\n",
        "test = test1.copy()\n",
        "data.drop(['P_emaildomain','R_emaildomain', 'TransactionID','TransactionDT'], axis = 1, inplace = True)\n",
        "test.drop(['P_emaildomain','R_emaildomain', 'TransactionID','TransactionDT'], axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gxvwnxZ5h9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rm_cols = ['V'+str(i) for i in range(1,340)]\n",
        "data.drop(rm_cols, axis = 1, inplace = True)\n",
        "test.drop(rm_cols, axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n9wJ1OS5iAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_col = ['TransactionAmt', 'dist1', 'dist2'] + ['C%d' % i for i in range(1,15)]\n",
        "cat_cols  = data.select_dtypes(include='object').columns\n",
        "numeric_cols  =  [c for c in data.columns if c not in cat_cols]\n",
        "non_log_cols = [c for c in numeric_cols if c not in log_col]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7SVzGg85iDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for c in log_col:\n",
        "  data[c] = data[c].apply(lambda x: np.log10(x+1e-1))\n",
        "  test[c] = test[c].apply(lambda x: np.log10(x+1e-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXApIpeo5iGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "data[numeric_cols[1:]] = ss.fit_transform(data[numeric_cols[1:]])\n",
        "test[numeric_cols[1:]] = ss.transform(test[numeric_cols[1:]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHAIKl035iI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = data.isnull().sum()/len(data)*100\n",
        "variables = data.columns\n",
        "variable = [ ]\n",
        "for i in range(0,len(variables)):\n",
        "    if a[i]<=60:   #setting the threshold as 20%\n",
        "        variable.append(variables[i])\n",
        "        \n",
        "d1 = data[variable]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwFbXQ-45iO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_vars = list(d1.select_dtypes(include='object').columns)\n",
        "for var in cat_vars:\n",
        "    cat_list='var'+'_'+ var\n",
        "    cat_list = pd.get_dummies(d1[var], prefix=var,drop_first =True)\n",
        "    df2=d1.join(cat_list)\n",
        "    d1 = df2\n",
        "data_vars=d1.columns.values.tolist()\n",
        "to_keep=[i for i in data_vars if i not in cat_vars]\n",
        "data_final=d1[to_keep]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEnyZgDV5iRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_final.drop('card6_debit or credit',inplace = True, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UPCKP2a76PS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data_final.drop('isFraud', axis = 1)\n",
        "y = data_final['isFraud']\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av0SfzhS76SL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testdata = test.copy()\n",
        "cat_vars_t = list(testdata.select_dtypes(include='object').columns)\n",
        "for var in cat_vars_t:\n",
        "    cat_list='var'+'_'+var\n",
        "    cat_list = pd.get_dummies(testdata[var], prefix=var,drop_first =True)\n",
        "    data1=testdata.join(cat_list)\n",
        "    testdata = data1\n",
        "        \n",
        "data_vars=testdata.columns.values.tolist()\n",
        "to_keep=[i for i in data_vars if i not in cat_vars]\n",
        "testdata=testdata[X_train.columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kwEVHM6AeKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.fillna(X_train.mean(), inplace = True)\n",
        "X_test.fillna(X_test.mean(), inplace = True)\n",
        "testdata.fillna(testdata.mean(), inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KB1GrbM76U6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "476869d4-fc06-4698-bbf8-9e3a40ce826c"
      },
      "source": [
        "!git clone https://github.com/h2oai/pystacknet"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pystacknet'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "Unpacking objects:   2% (1/42)   \rUnpacking objects:   4% (2/42)   \rUnpacking objects:   7% (3/42)   \rUnpacking objects:   9% (4/42)   \rUnpacking objects:  11% (5/42)   \rUnpacking objects:  14% (6/42)   \rUnpacking objects:  16% (7/42)   \rUnpacking objects:  19% (8/42)   \rUnpacking objects:  21% (9/42)   \rUnpacking objects:  23% (10/42)   \rUnpacking objects:  26% (11/42)   \rUnpacking objects:  28% (12/42)   \rUnpacking objects:  30% (13/42)   \rUnpacking objects:  33% (14/42)   \rUnpacking objects:  35% (15/42)   \rUnpacking objects:  38% (16/42)   \rUnpacking objects:  40% (17/42)   \rUnpacking objects:  42% (18/42)   \rUnpacking objects:  45% (19/42)   \rUnpacking objects:  47% (20/42)   \rUnpacking objects:  50% (21/42)   \rUnpacking objects:  52% (22/42)   \rUnpacking objects:  54% (23/42)   \rUnpacking objects:  57% (24/42)   \rUnpacking objects:  59% (25/42)   \rUnpacking objects:  61% (26/42)   \rUnpacking objects:  64% (27/42)   \rUnpacking objects:  66% (28/42)   \rUnpacking objects:  69% (29/42)   \rUnpacking objects:  71% (30/42)   \rUnpacking objects:  73% (31/42)   \rUnpacking objects:  76% (32/42)   \rremote: Total 42 (delta 0), reused 0 (delta 0), pack-reused 42\u001b[K\n",
            "Unpacking objects:  78% (33/42)   \rUnpacking objects:  80% (34/42)   \rUnpacking objects:  83% (35/42)   \rUnpacking objects:  85% (36/42)   \rUnpacking objects:  88% (37/42)   \rUnpacking objects:  90% (38/42)   \rUnpacking objects:  92% (39/42)   \rUnpacking objects:  95% (40/42)   \rUnpacking objects:  97% (41/42)   \rUnpacking objects: 100% (42/42)   \rUnpacking objects: 100% (42/42), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emqbkzTj9Bvj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d895e94-2cae-4e65-e019-f873efdb8487"
      },
      "source": [
        "cd pystacknet"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/train/pystacknet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dn4Yaao9TWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66_nwQJd76aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models=[ ######## First level ########\n",
        "            [\n",
        "             LGBMClassifier(boosting_type='gbdt',\n",
        "                        objective=\"binary\",\n",
        "                        metric=\"AUC\",\n",
        "                    \n",
        "                        boost_from_average=\"false\",\n",
        "                        learning_rate=0.0045,\n",
        "                        num_leaves=491,\n",
        "                        max_depth=20,\n",
        "                        min_child_weight=0.035,\n",
        "                        feature_fraction=0.38,\n",
        "                        bagging_fraction=0.42,\n",
        "                        min_data_in_leaf=100,\n",
        "                        max_bin=255,\n",
        "                        importance_type='split',\n",
        "                        reg_alpha=0.4,\n",
        "                        reg_lambda=0.65,\n",
        "                        bagging_seed=1,\n",
        "                        random_state=1,\n",
        "                        verbosity=-1,\n",
        "                        subsample=0.85,\n",
        "                        colsample_bytree=0.8,\n",
        "                        min_child_samples=79),\n",
        "             CatBoostClassifier(learning_rate=0.2,\n",
        "                            bagging_temperature=0.1, \n",
        "                            l2_leaf_reg=30,\n",
        "                            depth=12, \n",
        "                            max_bin=255,\n",
        "                            iterations=100,\n",
        "                            loss_function='Logloss',\n",
        "                            objective='Logloss',\n",
        "                            eval_metric=\"AUC\",\n",
        "                            bootstrap_type='Bayesian',\n",
        "                            random_seed=1,\n",
        "                            task_type = \"GPU\" ,\n",
        "                            early_stopping_rounds=10),\n",
        "             XGBClassifier(reg_alpha = 0, colsample_bytree = 0.75,eta = 0.125,gamma = 0.60,reg_lambda = 1.7,max_depth = 12,min_child_weight = 1.,n_estimators = 600,subsample =0.95 ,tree_method = 'gpu_hist',\n",
        "                           objective= 'binary:logistic',max_delta_step  = 1,seed=1)      \n",
        "            ],\n",
        "            ######## Second level ########\n",
        "            [RandomForestClassifier (n_estimators=500, criterion=\"entropy\", max_depth=10, random_state=1),\n",
        "            ]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnVBv0bw76dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pystacknet.pystacknet import StackNetClassifier\n",
        "\n",
        "model=StackNetClassifier(models, metric=\"auc\", folds=4,\n",
        "\trestacking=False,use_retraining=True, use_proba=True, \n",
        "\trandom_state=12345,n_jobs=1, verbose=1)\n",
        "\n",
        "model.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2_fbCoyGRLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_proba(X_test)\n",
        "\n",
        "y_pred = (y_pred>0.6).astype(int)\n",
        "data = pd.DataFrame(y_pred, columns = ['False', 'True'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1ae6NORGRO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['new']= 0\n",
        "for i in range(len(data)):\n",
        "  if data['False'][i] ==0:\n",
        "    data['new'][i]= 1\n",
        "  else:\n",
        "    data['new'][i] = 0\n",
        "\n",
        "y_pred = data['new']\n",
        "\n",
        "predictions = [value for value in y_pred]\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "AUC = roc_auc_score(y_test, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"AUC: %.2f%%\" % (AUC * 100.0))\n",
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8aWoLAAEyQ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "2e16820b-1aaf-4cdd-acb0-2943440a6369"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Sep 10 07:29:14 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    34W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOk9o7vq76gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iZZ4moW76j9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}